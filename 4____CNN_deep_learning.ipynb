{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26dca26a",
   "metadata": {},
   "source": [
    "### 0. Download the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bc6263",
   "metadata": {},
   "source": [
    "The data can be downloaded using the kagglehub package, and the downloaded files will then be moved to the current working directory. Make sure to install kagglehub if it's not already installed.\n",
    "This dataset consists of images from two categories: Cats and Dogs. It is well-suited for a binary classification task, with approximately 25,000 images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9705d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install kagglehub\n",
    "import os\n",
    "import shutil\n",
    "import kagglehub \n",
    "\n",
    "def download_kaggle(dataset_name):\n",
    "    # Download the dataset\n",
    "    path = kagglehub.dataset_download(dataset_name)\n",
    "\n",
    "    print(\"Path to dataset files:\", path)\n",
    "\n",
    "    # Get the current working directory\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "    # Iterate through all files in the `path` directory\n",
    "    for filename in os.listdir(path):\n",
    "        source_file = os.path.join(path, filename)  # Original file path\n",
    "        destination_file = os.path.join(current_dir, filename)  # Destination file path\n",
    "\n",
    "        # If the destination exists, check whether it's a file or a folder\n",
    "        if os.path.exists(destination_file):\n",
    "            if os.path.isfile(destination_file):  # If it's a file, remove it\n",
    "                os.remove(destination_file)\n",
    "            elif os.path.isdir(destination_file):  # If it's a folder, remove it recursively\n",
    "                shutil.rmtree(destination_file)\n",
    "\n",
    "        # Move file to the current directory\n",
    "        shutil.move(source_file, destination_file)\n",
    "        print(f\"Moved: {filename} -> {destination_file}\")\n",
    "\n",
    "    # Ensure `path` is empty before deleting the folder\n",
    "    if not os.listdir(path):  # Ensure the directory is empty\n",
    "        os.rmdir(path)\n",
    "        print(f\"Deleted empty folder: {path}\")\n",
    "\n",
    "    print(\"All files have been moved to the current directory!\")\n",
    "\n",
    "# download_kaggle(\"shaunthesheep/microsoft-catsvsdogs-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd08d4",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cac069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Show ERROR message only\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch\n",
    "import psutil\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import cv2\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9c6471",
   "metadata": {},
   "source": [
    "### 1. Split the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed97fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_directory(directory):\n",
    "    \"\"\"Clear all files and subdirectories inside the given directory.\"\"\"\n",
    "    if os.path.exists(directory):\n",
    "        for filename in os.listdir(directory):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.remove(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "\n",
    "def dataset_split(data_dir, test_size=0.2, random_seed=42):\n",
    "    # Get all subdirectories (categories) inside data_dir\n",
    "    subdirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d)) and d not in ['train', 'test']]\n",
    "    \n",
    "    if len(subdirs) < 2:\n",
    "        raise ValueError(\"At least two subdirectories (classes) are required in the dataset folder.\")\n",
    "\n",
    "    # Store file paths and corresponding labels\n",
    "    files = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, subdir in enumerate(subdirs):\n",
    "        subdir_path = os.path.join(data_dir, subdir)\n",
    "        subdir_files = [os.path.join(subdir_path, f) for f in os.listdir(subdir_path) if f.endswith('.jpg')]\n",
    "        \n",
    "        files.extend(subdir_files)\n",
    "        labels.extend([idx] * len(subdir_files))  # Use index as the label\n",
    "\n",
    "    # Split into training and test sets\n",
    "    train_files, test_files, train_labels, test_labels = train_test_split(files, labels, test_size=test_size, random_state=random_seed, stratify=labels)\n",
    "\n",
    "    # Define train/test directory paths\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "    # Clear the contents of train/ and test/ directories but keep the folders themselves\n",
    "    clear_directory(train_dir)\n",
    "    clear_directory(test_dir)\n",
    "\n",
    "    # Recreate train and test directories if they are removed\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    # Create subdirectories for each class inside train and test directories\n",
    "    for subdir in subdirs:\n",
    "        os.makedirs(os.path.join(train_dir, subdir), exist_ok=True)\n",
    "        os.makedirs(os.path.join(test_dir, subdir), exist_ok=True)\n",
    "\n",
    "    # Move files to their respective folders\n",
    "    for file, label in zip(train_files, train_labels):\n",
    "        shutil.copy(file, os.path.join(train_dir, subdirs[label]))  # Map index to subdirectory name\n",
    "\n",
    "    for file, label in zip(test_files, test_labels):\n",
    "        shutil.copy(file, os.path.join(test_dir, subdirs[label]))\n",
    "\n",
    "    print(\"The dataset has been successfully split into training and test sets!\")\n",
    "    print(f\"Total training samples: {len(train_files)}\")\n",
    "    print(f\"Total test samples: {len(test_files)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28d336d",
   "metadata": {},
   "source": [
    "### 2. Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_with_aspect_ratio(image, target_size=(150,150)):\n",
    "    \"\"\"\n",
    "    Resize the image while maintaining the aspect ratio and fill blank areas to match the target size.\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    aspect_ratio = width / height\n",
    "\n",
    "    # Calculate new dimensions\n",
    "    if aspect_ratio > 1:  # Width is greater than height\n",
    "        new_width = target_size[0]\n",
    "        new_height = int(target_size[0] / aspect_ratio)\n",
    "    else:  # Height is greater than width\n",
    "        new_height = target_size[1]\n",
    "        new_width = int(target_size[1] * aspect_ratio)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Fill blank areas\n",
    "    new_image = Image.new(\"RGB\", target_size, (255, 255, 255))  # White background\n",
    "    new_image.paste(resized_image, ((target_size[0] - new_width) // 2, (target_size[1] - new_height) // 2))\n",
    "\n",
    "    return new_image\n",
    "\n",
    "def load_supported_extensions(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        # Read all extensions and remove newline characters and whitespace\n",
    "        return [line.strip().lower() for line in f.readlines()]\n",
    "\n",
    "def process_images_in_directory(data_dir, target_size=(150,150), supported_doc='supported_extensions.txt'):\n",
    "    \"\"\"\n",
    "    Iterate through each image in the directory, resize it while maintaining the aspect ratio, \n",
    "    fill blank areas, save the modified image, and update file paths and labels.\n",
    "\n",
    "    Parameters:\n",
    "    - data_dir: Directory containing the dataset.\n",
    "    - target_width: Target width.\n",
    "    - target_height: Target height.\n",
    "    \"\"\"\n",
    "    # Get all class names in the directory\n",
    "    class_names = [d for d in os.listdir(os.path.join(data_dir, 'train')) if os.path.isdir(os.path.join(data_dir, 'train', d))]\n",
    "    \n",
    "    # Initialize lists to store file paths and labels\n",
    "    train_files = []\n",
    "    test_files = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "\n",
    "    # Load supported image formats\n",
    "    image_extensions = load_supported_extensions(supported_doc)\n",
    "\n",
    "    # Iterate through each class\n",
    "    for class_name in class_names:\n",
    "        # Get class directories for training and testing sets\n",
    "        train_class_dir = os.path.join(data_dir, 'train', class_name)\n",
    "        test_class_dir = os.path.join(data_dir, 'test', class_name)\n",
    "        \n",
    "        # Process images in both training and testing sets\n",
    "        for class_dir, files_list, labels_list in [\n",
    "            (train_class_dir, train_files, train_labels),\n",
    "            (test_class_dir, test_files, test_labels)\n",
    "        ]:\n",
    "\n",
    "            for image_name in os.listdir(class_dir):\n",
    "                image_path = os.path.join(class_dir, image_name)\n",
    "                # Check if the file is an image\n",
    "                if os.path.splitext(image_name)[1].lower() in image_extensions:\n",
    "                    # Open the image\n",
    "                    try:\n",
    "                        with Image.open(image_path) as img:\n",
    "                            # Resize and fill blank areas\n",
    "                            new_img = resize_with_aspect_ratio(img, target_size)\n",
    "                            \n",
    "                            # Overwrite and save the modified image\n",
    "                            new_img.save(image_path)  # Directly overwrite the original file\n",
    "                            \n",
    "                            # Update file path and label lists\n",
    "                            files_list.append(image_path)\n",
    "                            labels_list.append(class_name)\n",
    "                            \n",
    "                            # print(f\"Processed and saved: {image_path}\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"Unable to process image {image_path}: {e}\")\n",
    "                        # Delete unprocessable images\n",
    "                        os.remove(image_path)\n",
    "                        print(f\"Deleted unprocessable image {image_path}\")\n",
    "    \n",
    "    # Output updated file paths and labels\n",
    "    print(f\"Number of training set file paths: {len(train_files)}\")\n",
    "    print(f\"Number of testing set file paths: {len(test_files)}\")\n",
    "\n",
    "    # Save label information to a CSV file\n",
    "    label_data = [{'image_path': file, 'label': label} for file, label in zip(train_files + test_files, train_labels + test_labels)]\n",
    "    label_df = pd.DataFrame(label_data)\n",
    "    label_df.to_csv(os.path.join(data_dir, 'labels.csv'), index=False)\n",
    "    \n",
    "    return train_files, test_files, train_labels, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef608f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_batch_size(total_data, max_batch_size, image_size, validation_split=0.2, target_memory_usage=0.8):\n",
    "    \"\"\"\n",
    "    Dynamically calculates the batch size, considering GPU and memory limitations.\n",
    "    \n",
    "    Parameters:\n",
    "    - total_data: Total number of data points.\n",
    "    - max_batch_size: Maximum batch size.\n",
    "    - image_size: Size of each image (width, height, channels).\n",
    "    - validation_split: Fraction of data to be used for validation.\n",
    "    - target_memory_usage: Target memory usage percentage.\n",
    "\n",
    "    Returns:\n",
    "    - batch_size: Dynamically calculated batch size.\n",
    "    \"\"\"\n",
    "    # Get GPU memory size\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GPU found.\")\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory  # in bytes\n",
    "    else:\n",
    "        gpu_memory = 0  # Ignore if no GPU available\n",
    "\n",
    "    # Get total system memory size\n",
    "    system_memory = psutil.virtual_memory().total  # in bytes\n",
    "\n",
    "    # Estimate memory usage per image in bytes\n",
    "    image_memory = image_size[0] * image_size[1] * image_size[2] * 4  # Assuming each pixel is 4 bytes (float32)\n",
    "\n",
    "    # Calculate max batch size based on GPU or memory\n",
    "    if gpu_memory > 0:\n",
    "        max_gpu_batch_size = int(gpu_memory * target_memory_usage // image_memory)\n",
    "    else:\n",
    "        max_gpu_batch_size = total_data  # If no GPU, use system memory to control batch size\n",
    "    \n",
    "    # Calculate max batch size based on system memory\n",
    "    max_system_batch_size = int(system_memory * target_memory_usage // image_memory)\n",
    "\n",
    "    # Consider both GPU and system memory limitations\n",
    "    batch_size = min(max_batch_size, max_gpu_batch_size, max_system_batch_size, total_data // 10)\n",
    "\n",
    "    # Check if there is enough data for the validation split\n",
    "    if total_data * (1 - validation_split) < batch_size:\n",
    "        raise ValueError(f\"Not enough data to create a validation split. The total data size is too small for the batch size {batch_size}.\")\n",
    "\n",
    "    return batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ceaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_generators(data_dir, batch_size =64, validation_split=0.2, target_size=(150, 150)):\n",
    "    \"\"\"\n",
    "    Creates image data generators for training and validation sets with data augmentation.\n",
    "    Automatically detects the number of classes based on subdirectories in the 'train' directory.\n",
    "\n",
    "    Parameters:\n",
    "    - data_dir: Directory where the dataset is located. It should contain 'train' and optionally 'test' subdirectories.\n",
    "    - target_size: The size of the images to which the input images are resized. Defaults to (150, 150).\n",
    "    - batch_size: The number of samples per batch of data. Defaults to 64.\n",
    "    - validation_split: Fraction of the dataset to be reserved for validation. Defaults to 0.2 (20% validation set, 80% training set).\n",
    "\n",
    "    Returns:\n",
    "    - train_generator: A generator that yields batches of augmented image data for training.\n",
    "    - validation_generator: A generator that yields batches of image data for validation.\n",
    "\n",
    "    Notes:\n",
    "    - The function applies data augmentation techniques to the training data, including rescaling, rotation, shifting, shearing, zooming, and flipping.\n",
    "    - The validation set is only rescaled without augmentation.\n",
    "    - The function dynamically determines whether to use 'binary' or 'categorical' class mode based on the number of detected classes.\n",
    "    - If no subdirectories (representing classes) are found in 'train', an error is raised.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Data augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,         # Normalization\n",
    "        rotation_range=20,      # Rotation\n",
    "        width_shift_range=0.2,  # Horizontal shift\n",
    "        height_shift_range=0.2, # Vertical shift\n",
    "        shear_range=0.2,        # Shear transformation\n",
    "        zoom_range=0.2,         # Zoom\n",
    "        horizontal_flip=True,   # Horizontal flip\n",
    "        validation_split=validation_split  # Train/validation split\n",
    "    )\n",
    "\n",
    "    # Data augmentation is not applied to the validation set\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255, validation_split=validation_split)  # Only rescaling for validation set\n",
    "\n",
    "    # Data augmentation is not applied to the test set\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Dynamically detect the number of classes\n",
    "    class_names = os.listdir(os.path.join(data_dir, 'train'))\n",
    "   \n",
    "    if not class_names:\n",
    "        raise ValueError(\"No subdirectories found in the 'train' directory. Ensure that there are class subdirectories.\")\n",
    "\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    # Set class_mode based on number of classes\n",
    "    if num_classes == 2:\n",
    "        class_mode = 'binary'\n",
    "    else:\n",
    "        class_mode = 'categorical'\n",
    "    \n",
    "    # print(class_mode)\n",
    "\n",
    "    # Training set\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        os.path.join(data_dir, 'train'),  \n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode,\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    # Validation set\n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        os.path.join(data_dir, 'train'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode,\n",
    "        subset='validation',  # Use the validation subset\n",
    "        shuffle = False\n",
    "    )\n",
    "\n",
    "    # Test set\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        os.path.join(data_dir, 'test'),\n",
    "        target_size=target_size,  # Use the same targe size as training set\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # No labels in test set\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_generator, validation_generator, test_generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c2dabd",
   "metadata": {},
   "source": [
    "### 3. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8847259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model\n",
    "def build_model(\n",
    "    input_shape=(150, 150, 3), \n",
    "    conv_layers=[(32, (3,3)), (64, (3,3)), (128, (3,3))], \n",
    "    pool_size=(2,2),\n",
    "    dense_units=512,\n",
    "    dropout_rate=0.5,\n",
    "    output_units=1,\n",
    "    output_activation='sigmoid',\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "):\n",
    "    model = Sequential()\n",
    " \n",
    "    # Add convolutional and pooling layers\n",
    "    for i, (filters, kernel_size) in enumerate(conv_layers):\n",
    "        if i == 0:\n",
    "            model.add(Conv2D(filters, kernel_size, activation='relu', input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(Flatten())  # Flatten layer\n",
    "    model.add(Dense(dense_units, activation='relu'))  # Fully connected layer\n",
    "    model.add(Dropout(dropout_rate))  # Dropout layer\n",
    "    model.add(Dense(output_units, activation=output_activation))  # Output layer\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    \n",
    "    # Print model structure\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81e3ac8",
   "metadata": {},
   "source": [
    "### 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "142e18b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_save_as, model, train_generator, validation_generator, csv_log, epochs = 10):\n",
    "    # Create a CSVLogger callback to save the training history to a local CSV file\n",
    "    csv_logger = CSVLogger(csv_log, append=True)\n",
    "    \n",
    "    # Train the model and use the CSVLogger callback\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks= [csv_logger]\n",
    "    )\n",
    "\n",
    "    # After training, the training history will be saved in 'training_history.csv'\n",
    "    print(\"history has been save in f'{csv_log}'. \")\n",
    "\n",
    "    # Save the model using Keras \n",
    "    model.save(f\"{model_save_as}\")\n",
    "\n",
    "    print(\"model has been save in f'{model_save_as}'.\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac0eef2",
   "metadata": {},
   "source": [
    "### 5. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf36dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(history):\n",
    "\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b285d6b6",
   "metadata": {},
   "source": [
    "### 6. Predict on the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd9bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data():\n",
    "\n",
    "    img_path = './PetImages/test/cat/32.jpg'\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    if prediction[0] > 0.5:\n",
    "        print(\"Prediction: üê∂\")\n",
    "    else:\n",
    "        print(\"Prediction: üê±\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca8a686",
   "metadata": {},
   "source": [
    "### Further exploration on model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc0e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(axes, history_df):\n",
    "    \"\"\"Plots accuracy and loss curves in the given axes.\"\"\"\n",
    "    if axes is None or len(axes)<2:\n",
    "        return\n",
    "    ax1, ax2 = axes\n",
    "    # Accuracy\n",
    "    ax1.plot(history_df[\"epoch\"], history_df[\"accuracy\"], label=\"Training Accuracy\")\n",
    "    ax1.plot(history_df[\"epoch\"], history_df[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "    ax1.set_title(\"Accuracy Curve\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Loss\n",
    "    ax2.plot(history_df[\"epoch\"], history_df[\"loss\"], label=\"Training Loss\")\n",
    "    ax2.plot(history_df[\"epoch\"], history_df[\"val_loss\"], label=\"Validation Loss\")\n",
    "    ax2.set_title(\"Loss Curve\")\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.legend()\n",
    "\n",
    "def plot_confusion_matrix(ax, y_true, y_pred, class_names):\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "def plot_roc_curve(ax, y_true, y_scores):\n",
    "  \n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    ax.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "    ax.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC Curve')\n",
    "    ax.legend()\n",
    "\n",
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size height * width\n",
    "    img = keras.utils.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (height, width, 3)\n",
    "    array = keras.utils.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, height, width, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    array = array / 255.0  # Normalize pixel values to the range [0, 1] for neural network processing\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names):\n",
    "    \"\"\"\n",
    "    Generate a Grad-CAM heatmap for a given image.\n",
    "    \n",
    "    Args:\n",
    "        img_array (numpy array): Preprocessed input image.\n",
    "        model (tf.keras.Model): Trained model.\n",
    "        last_conv_layer_name (str): Name of the last convolutional layer.\n",
    "        classifier_layer_names (list of str): List of classifier layer names after the convolutional layer.\n",
    "    \n",
    "    Returns:\n",
    "        numpy array: Normalized heatmap.\n",
    "    \"\"\"\n",
    "    # Extract the last convolutional layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "    # Define a classifier model from the output of the last convolutional layer\n",
    "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "    x = classifier_input\n",
    "    for layer_name in classifier_layer_names:\n",
    "        x = model.get_layer(layer_name)(x)\n",
    "    classifier_model = keras.Model(classifier_input, x)\n",
    "\n",
    "    # Compute gradients of the predicted class score with respect to feature maps\n",
    "    with tf.GradientTape() as Tape:\n",
    "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "        Tape.watch(last_conv_layer_output)\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        top_pred_index = tf.argmax(preds[0])\n",
    "        top_class_channel = preds[:, top_pred_index]\n",
    "\n",
    "    grads = Tape.gradient(top_class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2)).numpy()\n",
    "\n",
    "    # Weight the feature map channels by their importance\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)  # Normalize heatmap\n",
    "    return heatmap\n",
    "\n",
    "def plot_grad_cam(axes, misclassified_dir, target_size, model, last_conv_layer_name, classifier_layer_names, alpha):\n",
    "    \"\"\"\n",
    "    Plot Grad-CAM heatmap and overlay images on given axes.\n",
    "    \n",
    "    Args:\n",
    "        axes (list): List of matplotlib axes.\n",
    "        misclassified_dir (str): Directory containing misclassified images.\n",
    "        target_size (tuple): Target size for image preprocessing.\n",
    "        model (tf.keras.Model): Trained model.\n",
    "        last_conv_layer_name (str): Name of the last convolutional layer.\n",
    "        classifier_layer_names (list of str): List of classifier layer names.\n",
    "        alpha (float): Weighting factor for heatmap overlay.\n",
    "    \"\"\"\n",
    "    if axes is None or len(axes) < 3:\n",
    "        return\n",
    "    \n",
    "    img_paths = [os.path.join(subdir, file) for subdir, _, files in os.walk(misclassified_dir) for file in files]\n",
    "    n = len(img_paths)\n",
    "    if len(axes) < n * 3:\n",
    "        print(f\"Not enough axes. Required at least {n * 3}.\")\n",
    "        return\n",
    "    \n",
    "    for i, img_path in enumerate(img_paths):\n",
    "        ax0, ax1, ax2 = axes[i * 3], axes[i * 3 + 1], axes[i * 3 + 2]\n",
    "        img_array = get_img_array(img_path, target_size)\n",
    "        heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names)\n",
    "\n",
    "        img = keras.utils.load_img(img_path)\n",
    "        img = keras.utils.img_to_array(img)\n",
    "        ax0.imshow(img.astype(np.uint8))\n",
    "        ax0.axis('off')\n",
    "        ax0.set_title('Original Image')\n",
    "\n",
    "        heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "        \n",
    "        superimposed_img = heatmap * alpha + img * (1 - alpha)\n",
    "        superimposed_img = np.clip(superimposed_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "        ax1.imshow(heatmap, cmap='viridis')\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title('Grad-CAM Heatmap')\n",
    "\n",
    "        ax2.imshow(superimposed_img)\n",
    "        ax2.axis('off')\n",
    "        ax2.set_title('Grad-CAM Overlay')\n",
    "\n",
    "def plot_tsne(ax, model, test_generator, class_names,  n_components, random_state, perplexity, n_iter):\n",
    "    \"\"\"\n",
    "    Plots t-SNE visualization of feature embeddings from the CNN model.\n",
    "    \n",
    "    Args:\n",
    "        ax (matplotlib axis): Axis to plot the t-SNE visualization.\n",
    "        model (tf.keras.Model): Trained CNN model.\n",
    "        test_generator (ImageDataGenerator): Test data generator.\n",
    "        class_names (list): List of class names (e.g., ['cat', 'dog']).\n",
    "    \"\"\"\n",
    "    # Extract features from the model (before the final classification layer)\n",
    "    feature_extractor = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "    features = feature_extractor.predict(test_generator)\n",
    "    labels = test_generator.classes\n",
    "\n",
    "    # Apply t-SNE to reduce features to 2D\n",
    "    tsne = TSNE(n_components=n_components, random_state=random_state, perplexity=perplexity, n_iter=n_iter)\n",
    "    features_2d = tsne.fit_transform(features)\n",
    "\n",
    "    # Plot t-SNE results\n",
    "    scatter = ax.scatter(features_2d[:, 0], features_2d[:, 1], c=labels, cmap='viridis', s=20)\n",
    "    ax.set_title('t-SNE Visualization of Feature Embeddings')\n",
    "    ax.set_xlabel('t-SNE Dimension 1')\n",
    "    ax.set_ylabel('t-SNE Dimension 2')\n",
    "\n",
    "    # plt.colorbar(scatter, ax=ax, ticks=range(len(class_names)), label='Class')\n",
    "    # Create a colorbar with class names\n",
    "    cbar = plt.colorbar(scatter, ax=ax, ticks=range(len(class_names)))\n",
    "    cbar.set_ticklabels([f'{class_names[i]} ({i})' for i in range(len(class_names))])  # Add both class names and labels\n",
    "    cbar.set_label('Class')\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "def evaluation_visualizations(log_csv, model_save_as, test_generator, data_dir, target_size, misclassified_dir, max_per_class, n_components, random_state, perplexity, n_iter):\n",
    "    \"\"\"Dynamically generates a grid and fills it with various visualization functions.\"\"\"\n",
    "    # Load the training history from CSV\n",
    "    history_df = pd.read_csv(log_csv)\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model(model_save_as) \n",
    "\n",
    "    num_classes = len(test_generator.class_indices)  # Get the number of classes\n",
    "    # Retrieve class names\n",
    "    class_names = list(test_generator.class_indices.keys())\n",
    "    print(\"Class names:\", class_names)\n",
    "\n",
    "    # Get predictions\n",
    "    y_pred = (model.predict(test_generator) > 0.5).astype(int)\n",
    "    y_scores = model.predict(test_generator)  # Get probabilities for class 1\n",
    "\n",
    "    if num_classes > 2:\n",
    "        # For multi-class classification, convert to class indices\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    y_true = test_generator.classes  # Get true labels\n",
    "\n",
    "    # **Save misclassified samples**\n",
    "    # Clear the directory\n",
    "    clear_directory(misclassified_dir)\n",
    "    os.makedirs(misclassified_dir, exist_ok=True)\n",
    "\n",
    "    y_pred = y_pred.ravel()\n",
    "    y_true = y_true.ravel()\n",
    "\n",
    "    misclassified_indices = np.where(y_true != y_pred)[0]  # Indices of misclassified samples\n",
    "    misclassified_counts = {}  # Track misclassification count per class pair\n",
    "    total_misclassified_images = 0  # Variable to track the total number of misclassified images\n",
    "\n",
    "    for idx in misclassified_indices:\n",
    "        true_label = int(y_true[idx])\n",
    "        pred_label = int(y_pred[idx])\n",
    "\n",
    "        # Track the misclassification count for (true_label, pred_label) pair\n",
    "        misclass_key = (true_label, pred_label)\n",
    "        if misclassified_counts.get(misclass_key, 0) >= max_per_class:\n",
    "            continue\n",
    "\n",
    "        # Get image path\n",
    "        img_path = os.path.join(data_dir, test_generator.filenames[idx])  \n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Ensure class directory exists\n",
    "        class_dir = os.path.join(misclassified_dir, f\"class_{class_names[true_label]}_pred_{class_names[pred_label]}\")\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        # Save the misclassified image\n",
    "        save_path = os.path.join(class_dir, f\"{misclassified_counts.get(misclass_key, 0)}.png\")\n",
    "        img.save(save_path)\n",
    "\n",
    "        # Update misclassification count\n",
    "        misclassified_counts[misclass_key] = misclassified_counts.get(misclass_key, 0) + 1\n",
    "        total_misclassified_images += 1 \n",
    "    print(f\"Saved {total_misclassified_images} misclassified images in '{misclassified_dir}'\")\n",
    "\n",
    "    # Find the last Conv2D layer\n",
    "    last_conv_layer_name = None\n",
    "    for layer in reversed(model.layers):  # Iterate from the last layer\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            last_conv_layer_name = layer.name\n",
    "            break\n",
    "\n",
    "    print(\"Last convolutional layer:\", last_conv_layer_name)\n",
    "\n",
    "    # Get classifier layer names (layers after the last Conv2D layer)\n",
    "    classifier_layer_names = []\n",
    "    found_conv_layer = False\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if layer.name == last_conv_layer_name:\n",
    "            found_conv_layer = True  # Mark when the last Conv2D layer is found\n",
    "        if found_conv_layer:\n",
    "            classifier_layer_names.append(layer.name)\n",
    "\n",
    "    # Remove the first element (which is the last Conv2D layer itself)\n",
    "    classifier_layer_names.pop(0)\n",
    "\n",
    "    print(\"Classifier layers:\", classifier_layer_names)\n",
    "\n",
    "    alpha = 0.4\n",
    "    # List of visualization functions with parameters\n",
    "    viz_functions = [\n",
    "        {\"func\": plot_accuracy_loss, \"params\": {\"history_df\": history_df}, \"ax_count\": 2},\n",
    "        {\"func\": plot_confusion_matrix, \"params\": {\"y_true\": y_true, \"y_pred\": y_pred, \"class_names\": class_names}, \"ax_count\": 1},\n",
    "        {\"func\": plot_roc_curve, \"params\": {\"y_true\": y_true, \"y_scores\": y_scores}, \"ax_count\": 1},\n",
    "        {\"func\": plot_grad_cam, \n",
    "            \"params\": {\n",
    "                \"misclassified_dir\": misclassified_dir, \n",
    "                \"target_size\": target_size, \n",
    "                \"model\": model,\n",
    "                \"last_conv_layer_name\": last_conv_layer_name,\n",
    "                \"classifier_layer_names\": classifier_layer_names,\n",
    "                \"alpha\": alpha\n",
    "            }, \n",
    "            \"ax_count\": total_misclassified_images * 3\n",
    "        },\n",
    "        {\"func\": plot_tsne, \n",
    "            \"params\": {\n",
    "                \"model\": model, \n",
    "                \"test_generator\": test_generator,\n",
    "                \"class_names\": class_names,\n",
    "                \"n_components\": n_components, \n",
    "                \"random_state\": random_state, \n",
    "                \"perplexity\": perplexity, \n",
    "                \"n_iter\": n_iter\n",
    "                }, \n",
    "            \"ax_count\": 1\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    # Dynamically determine grid size\n",
    "    total_rows = sum(v[\"ax_count\"] // 3 if v[\"func\"] == plot_grad_cam else 1 for v in viz_functions)\n",
    "    fig, axes = plt.subplots(nrows=total_rows, ncols=3, figsize=(18, 5 * total_rows))    \n",
    "    \n",
    "    axes = np.array(axes).flatten()  # Flatten axes array for easy indexing\n",
    "\n",
    "    # Execute visualization functions\n",
    "    i = 0\n",
    "    for viz_info in viz_functions:\n",
    "        func = viz_info[\"func\"]\n",
    "        params = viz_info[\"params\"]\n",
    "        ax_count = viz_info[\"ax_count\"]\n",
    "        \n",
    "        if ax_count == 1:\n",
    "            func(axes[i], **params)  # Use a single axis\n",
    "        else:\n",
    "            func(axes[i:i+ax_count], **params)  # Pass multiple axes\n",
    "        i += ax_count  # Increment index\n",
    "\n",
    "    # Remove unused subplots\n",
    "    for j in range(i, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1d28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_folder      = 'PetImages'\n",
    "    data_dir         = './' + data_folder\n",
    "    model_type       = 'cnn'\n",
    "    model_save_as    = data_folder + model_type + '.keras'\n",
    "    test_size        = 0.2\n",
    "    random_seed      = 42\n",
    "    target_size      = (150,150)\n",
    "    supported_doc    = 'supported_extensions.txt'\n",
    "    csv_log          = 'training_history.csv'\n",
    "    misclassified_dir= os.path.join(data_dir, 'misclassified_images')  # Store misclassified images in data_dir\n",
    "    max_per_class    = 10 # Maximum of 10 misclassified images per category\n",
    "    n_components     = 2 # Set the number of dimensions for the output (2D for visualization)\n",
    "    random_state     = 42 # Set the seed for reproducibility of results\n",
    "    perplexity       = 30 # Control the balance between local and global data relationships\n",
    "    n_iter           = 1000 # Set the number of iterations for the optimization process\n",
    "\n",
    "\n",
    "    # 0. Download the dataset\n",
    "    download_kaggle(\"shaunthesheep/microsoft-catsvsdogs-dataset\")\n",
    "\n",
    "    # 1. Split the dataset\n",
    "    dataset_split(data_dir, test_size, random_seed)\n",
    "\n",
    "    # 2. Data Augmentation\n",
    "    # 2.1 Resize the images\n",
    "    train_files, test_files, train_labels, test_labels = process_images_in_directory(data_dir, target_size, supported_doc)\n",
    "\n",
    "    # 2.2 Calculate the batch size\n",
    "    total_data = len(train_files)\n",
    "    image_size = (150, 150, 3)  # Assuming each image has dimensions 150x150 with 3 channels\n",
    "    validation_split = 0.2\n",
    "    target_memory_usage = 0.8\n",
    "    batch_size = calculate_batch_size(total_data, max_batch_size, image_size, validation_split, target_memory_usage)\n",
    "    # print(\"batch_size: \", batch_size)\n",
    "    \n",
    "    # 2.3 Create Image Generators\n",
    "    train_generator, validation_generator, test_generator = create_image_generators(data_dir, batch_size, validation_split, target_size)\n",
    "    \n",
    "    # 3. Build a CNN model\n",
    "    num_classes = len(train_generator.class_indices)  # Get the number of categories\n",
    "    if num_classes == 2:\n",
    "        output_units = 1\n",
    "        output_activation = 'sigmoid'\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        output_units = num_classes\n",
    "        output_activation = 'softmax'\n",
    "        loss = 'categorical_crossentropy'\n",
    "\n",
    "    input_shape = (150, 150, 3)\n",
    "    conv_layers = [(32, (3,3)), (64, (3,3)), (128, (3,3)), (256, (3,3))]\n",
    "    pool_size = (2,2)\n",
    "    dense_units = 1024\n",
    "    dropout_rate = 0.4\n",
    "    optimizer = 'adam'\n",
    "    metrics = ['accuracy']\n",
    "\n",
    "    cnn_model = build_model(\n",
    "        input_shape, \n",
    "        conv_layers, \n",
    "        pool_size,\n",
    "        dense_units,\n",
    "        dropout_rate,\n",
    "        output_units,\n",
    "        output_activation,\n",
    "        optimizer,\n",
    "        loss,\n",
    "        metrics)\n",
    "    \n",
    "    # 4. Train the model\n",
    "    epochs = 10\n",
    "    history = train_model(model_save_as, cnn_model, train_generator, validation_generator, csv_log, epochs)\n",
    "    \n",
    "    # 5. Evaluate the model\n",
    "    evaluate_model(history)\n",
    "    \n",
    "    # 6. Predict on new data\n",
    "    # Load the model\n",
    "    model = load_model(model_save_as)  # Replace with your model path\n",
    "    \n",
    "    # Load and preprocess an image\n",
    "    img_path = './PetImages/test/cat/32.jpg'\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(img_array)\n",
    "    if prediction[0] > 0.5:\n",
    "        print(\"Prediction: Dog üê∂\")\n",
    "    else:\n",
    "        print(\"Prediction: Cat üê±\")\n",
    "\n",
    "\n",
    "    # Further exploration on model evaluation\n",
    "    evaluation_visualizations(csv_log, model_save_as, test_generator, data_dir, target_size, misclassified_dir, max_per_class, n_components, random_state, perplexity, n_iter)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
