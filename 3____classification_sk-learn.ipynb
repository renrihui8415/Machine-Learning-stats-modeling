{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc617833",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### scikit-learn/classification ######\n",
    "# 0. Visualize dataset according to data characteristics\n",
    "# 1. Import Required Libraries\n",
    "# 2. Load the Dataset (Covertype dataset)\n",
    "# 3. Split the Data\n",
    "# 4. Define Classification Models\n",
    "# 5. Train and Evaluate Models\n",
    "# 6. Return the Best Model and Visualize Performance Metrics\n",
    "# 7. Predicting with the best model\n",
    "###### scikit-learn/classification ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6339b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Visualize dataset \n",
    "\n",
    "print(\"Starting to create Pair Plot...\")\n",
    "\n",
    "# 0.1 Pairplot\n",
    "sns.pairplot(data_plot, hue=target_variable, palette='bwr')\n",
    "plt.title = \"1. Pair Plot\\nsk-learn\"\n",
    "plt.show()\n",
    "\n",
    "# 0.2 Histograms\n",
    "# Optimized Histograms (top features)\n",
    "top_features = feature_importance_df['feature'].tolist()[:top_importances]  # Assuming num_top_features is defined\n",
    "# top_features = feature_importance_df['feature'].tolist()\n",
    "\n",
    "selected_data_without_y = transformed_data[top_features]\n",
    "data_train, data_plot = train_test_split(selected_data_without_y, test_size=0.01, random_state=42)\n",
    "data_plot.hist(bins=15, figsize=(15, 10))\n",
    "plt.title = \"2. Histograms\\nsk-learn\"\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 0.3 Heatmap\n",
    "data_corr = data_plot.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data_corr, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title='3. Correlation Heatmap(Top Features)\\nsk-learn'\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f6d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Required Libraries\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') # mute warning messages\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, matthews_corrcoef\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_recall_curve,precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import clone\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib.colors import ListedColormap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c530f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the dataset\n",
    "# Subfunction to load the dataset\n",
    "def capitalize_first_letter(word):\n",
    "    # Capitalize the first letter and convert the rest of the word to lowercase\n",
    "    return word[:1].upper() + word[1:].lower()\n",
    "\n",
    "def load_dataset(dataset_name):\n",
    "    try: \n",
    "        capitalized_name = capitalize_first_letter(dataset_name)\n",
    "        if capitalized_name == 'Covertype':\n",
    "            data = fetch_covtype()\n",
    "        elif capitalized_name == 'Higgs':\n",
    "            data = fetch_openml(name='higgs', version=2)\n",
    "        else: \n",
    "            data = load_data(capitalized_name)\n",
    "        return data\n",
    "    except:\n",
    "        return 'No dataset named ' + dataset_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Pipeline fitting\n",
    "# 3.1 Subfunctions\n",
    "def get_importances(best_model_name,model_step_name):\n",
    "    # Load pipeline before use\n",
    "    pipeline = load(f'{best_model_name}.joblib')\n",
    "    model = pipeline.named_steps[model_step_name]\n",
    "\n",
    "    # Get all attributes from the model object\n",
    "    attributes = dir(model)\n",
    "\n",
    "    # for attribute in attributes:\n",
    "    #     print(attribute)\n",
    "    importances = None\n",
    "    if 'feature_importances_' in attributes:\n",
    "        print(f\"The attribute has been found: feature_importances_\")\n",
    "        return model.feature_importances_\n",
    "\n",
    "    if 'coef_' in attributes:\n",
    "        if len(model.coef_) == 1:  # For binary classification\n",
    "            print(f\"The attribute has been found: coef_ (binary classification)\")\n",
    "            return np.abs(model.coef_[0])\n",
    "        else:  # For multiclass classification, take the average\n",
    "            print(f\"The attribute has been found: coef_ (multiclass classification)\")\n",
    "            return np.abs(model.coef_.mean(axis=0))\n",
    "\n",
    "    if 'best_estimator_' in attributes:\n",
    "        best_estimator = model.best_estimator_\n",
    "        best_estimator_attributes = dir(best_estimator)\n",
    "        # for best_estimator_attribute in best_estimator_attributes:\n",
    "        #     print(best_estimator_attribute)\n",
    "            \n",
    "        if 'feature_importances_' in best_estimator_attributes:\n",
    "            print(f\"The attribute has been found in best_estimator_: feature_importances_\")\n",
    "            return model.best_estimator_.feature_importances_\n",
    "\n",
    "        if 'coef_' in best_estimator_attributes:\n",
    "            if len(best_estimator.coef_) == 1:  # For binary classification\n",
    "                print(f\"The attribute has been found in best_estimator_: coef_ (binary classification)\")\n",
    "                return np.abs(model.best_estimator_.coef_[0])\n",
    "               \n",
    "            else:  # For multiclass classification, take the average\n",
    "                print(f\"The attribute has been found in best_estimator_: coef_ (multiclass classification)\")\n",
    "                return np.abs(model.best_estimator_.coef_.mean(axis=0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Pipeline fitting\n",
    "def fit_classification_models(X,y,testsize,model_step_name,preprocessor, target_variable, random_seed=42, top_importances=4):\n",
    "    # Split the Data\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testsize, stratify=y, random_state=42)\n",
    "\n",
    "        print(f\"X_train contains {len(X_train)} rows.\")\n",
    "        print(f\"X_test contains {len(X_test)} rows.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while splitting the data: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # 4. Define Classification Models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=10000),\n",
    "        'Decision Tree Classifier': DecisionTreeClassifier(),\n",
    "        'Random Forest Classifier': RandomForestClassifier(),\n",
    "        'Gradient Boosting Classifier': GradientBoostingClassifier(),\n",
    "        'Support Vector Classifier': SVC(probability=True),\n",
    "        'K-Neighbors Classifier': KNeighborsClassifier(),\n",
    "        'Neural Network': MLPClassifier(),  # Example, use appropriate neural network model\n",
    "        'Regularized Linear Model': LogisticRegression(max_iter=10000, penalty='l2'),  # Example, use appropriate regularized linear model\n",
    "    }\n",
    "    # Define hyperparameters for models where applicable\n",
    "    # Determine if the dataset is large or small based on the length of X_train\n",
    "    if len(X_train) > 1000:  # Adjust this threshold based on your specific dataset size\n",
    "        start, stop, step = 10, 51, 10  # Start from 10, go up to 50 (inclusive), with a step of 10\n",
    "    else:\n",
    "        start, stop, step = 3, 10, 2 # Start from 3, go up to 9 (inclusive), with a step of 2\n",
    "    # Generate the continuous k_range\n",
    "    k_range = list(range(start, stop, step))\n",
    "\n",
    "    def generate_hidden_layer_sizes(X_train):\n",
    "        # Determine the size of the training data\n",
    "        num_features = X_train.shape[1]\n",
    "        \n",
    "        # Define a range of hidden layer sizes based on the size of the training data\n",
    "        hidden_layer_sizes = [\n",
    "            tuple(np.random.randint(50, 101, size=np.random.randint(1, num_features + 1))) \n",
    "            for _ in range(3)\n",
    "        ]\n",
    "        return hidden_layer_sizes\n",
    "    \n",
    "    # Define a function to generate dynamic parameter values\n",
    "    def generate_param_range(start, end, step):\n",
    "        return np.arange(start, end + step, step)\n",
    "\n",
    "    # Define the dynamic parameter ranges\n",
    "    alpha_range = generate_param_range(0.1, 10, 0.1)\n",
    "\n",
    "    # add poly and interaction for logistic regression:\n",
    "    # Define the dynamic parameter ranges for logistic regression\n",
    "  \n",
    "    degree_list = [1]\n",
    "    model_params = {\n",
    "        'Logistic Regression': {'C': [10**i for i in range(-3, 4)]},  # C values ranging from 0.001 to 1000,  \n",
    "        'Decision Tree Classifier': {'max_depth': [3, 5, None]},\n",
    "        'Random Forest Classifier': {'n_estimators': [50, 100, 200]},\n",
    "        'Gradient Boosting Classifier': {'n_estimators': [50, 100, 200], 'learning_rate': [0.1, 0.5, 1.0]},\n",
    "        'Support Vector Classifier': {'C': [10**i for i in range(-3, 4)], 'kernel': ['linear', 'rbf']},\n",
    "        'K-Neighbors Classifier': {'n_neighbors': k_range} ,\n",
    "        'Neural Network': {'hidden_layer_sizes': generate_hidden_layer_sizes(X_train)} ,\n",
    "        'Regularized Linear Model': {'C': alpha_range}\n",
    "    }\n",
    "    # 5. Train and Evaluate Models\n",
    "    best_model_info = None\n",
    "    best_k =None\n",
    "    classification_pipelines ={}\n",
    "    for name, model in models.items():\n",
    "        if name == 'Logistic Regression':\n",
    "            for degree in degree_list:\n",
    "                classification_pipelines[f'{name} (Degree {degree})'] = Pipeline([\n",
    "                    ('preprocessor',preprocessor),\n",
    "                    (\"poly_features\", PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "                    (f\"{model_step_name}\",  GridSearchCV(model, model_params[name], cv=5))\n",
    "                ])\n",
    "   \n",
    "        else:\n",
    "            classification_pipelines[f'{name} (Degree 1)'] = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                (f\"{model_step_name}\", GridSearchCV(model, model_params[name], cv=5))\n",
    "            ])\n",
    "       \n",
    "    metrics_list =[]   \n",
    "    for name, pipeline in classification_pipelines.items():\n",
    "        try:\n",
    "            # 5. Train the model\n",
    "    \n",
    "            print(f\"Start training {name}...\")\n",
    "            start_time =time.time()\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            print(\"Training Complete.\")\n",
    "            # Predict on X_test and save the pipeline in the disk\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "            minutes = int(execution_time // 60)\n",
    "            seconds = int(execution_time % 60)\n",
    "\n",
    "            print(\"Execution time:\", minutes, \"minutes and\", seconds, \"seconds\")\n",
    "            # Calculate the metrics\n",
    "            # print(\"Start predicting on test data and calculating metris...\")\n",
    "\n",
    "            def calculate_metrics(name, y_test, y_pred):\n",
    "                metrics_dict = {}\n",
    "                if len(set(y_test)) == 2 and set(y_test) == {0, 1}:\n",
    "                    # Binary classification\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    precision = precision_score(y_test, y_pred)\n",
    "                    recall = recall_score(y_test, y_pred)\n",
    "                    f1 = f1_score(y_test, y_pred)\n",
    "                    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "                    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "                    specificity = tn / (tn + fp) if tn + fp != 0 else None  # Handle division by zero\n",
    "                    cm = confusion_matrix(y_test, y_pred)\n",
    "                    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "                else:\n",
    "                    # non-binary, multiclass classification\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "                    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "                    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "                    roc_auc = specificity = cm = mcc = None\n",
    "                # Add all metrics to the dictionary\n",
    "                metrics_dict = {\n",
    "                    'model': name,\n",
    "                    'Accuracy': accuracy if accuracy is not None else float('-inf'),\n",
    "                    'Precision': precision if precision is not None else float('-inf'),\n",
    "                    'Recall': recall if recall is not None else float('-inf'),\n",
    "                    'F1 Score': f1 if f1 is not None else float('-inf'),\n",
    "                    'ROC-AUC Score': roc_auc if roc_auc is not None else float('-inf'),\n",
    "                    'Specificity': specificity if specificity is not None else float('-inf'),\n",
    "                    'Confusion Matrix': cm if cm is not None else float('-inf'),\n",
    "                    'MCC': mcc if mcc is not None else float('-inf')\n",
    "                }\n",
    "                return metrics_dict\n",
    "        \n",
    "            metrics_list.append(calculate_metrics(name, y_test, y_pred))\n",
    "            # Save the pipeline in the disk\n",
    "            dump(pipeline, f\"{name}.joblib\")\n",
    "   \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while training and evaluating the {name} model: {e}\")\n",
    "\n",
    "    # Sort the scores list based on the 'Accuracy' metric in descending order\n",
    "    sorted_scores = sorted(metrics_list, key=lambda x: (x['Accuracy'], x['Precision'], x['Recall'], x['F1 Score'], x['ROC-AUC Score'], x['Specificity'], x['MCC']), reverse=True)\n",
    "    print(sorted_scores)\n",
    "    \n",
    "    # 6. Return the Best Model and Visualize Performance Metrics\n",
    "\n",
    "    best_model_info = sorted_scores[0]\n",
    "    best_model_name = best_model_info['model']\n",
    "    print(f'Best model found: {best_model_name}')\n",
    "    print(best_model_info)\n",
    "\n",
    "    # Get the best value of K from the pipeline\n",
    "    if  'K-Neighbors Classifier' in best_model_name:\n",
    "        # Load pipeline before use\n",
    "        pipeline = load(f'{best_model_name}.joblib')\n",
    "        best_k = pipeline.named_steps[model_step_name].best_params_['n_neighbors']\n",
    "        print(f'best-k is {best_k}')\n",
    "     \n",
    "\n",
    "    # # Delete all other joblib files\n",
    "    # for name, pipeline in classification_pipelines.items():\n",
    "    #     for model_name in best_models_name: \n",
    "    #         if name == model_name:\n",
    "    #             pass\n",
    "    #         else: \n",
    "    #             joblib_file = f'{name}.joblib'\n",
    "    #             if os.path.exists(joblib_file):\n",
    "    #                 os.remove(joblib_file)\n",
    "\n",
    "    #  Attributes in machine learning models, particularly those from libraries like scikit-learn, \n",
    "    # typically do not include constants or non-functional attributes directly related to the internal logic of classification models. \n",
    "\n",
    "    import re\n",
    "    match = re.search(r'Degree (\\d+)', best_model_name)\n",
    "    degree = int(match.group(1))\n",
    "    # print(f\"Degree = {degree}\")\n",
    "    if degree ==1:\n",
    "        feature_names =X_train.columns\n",
    "    else: \n",
    "        # Load pipeline before use\n",
    "        pipeline = load(f'{best_model_name}.joblib')\n",
    "        poly_features = pipeline.named_steps['poly_features']\n",
    "        column_names = X_train.columns.tolist() \n",
    "        feature_names = poly_features.get_feature_names_out(input_features=column_names)\n",
    "\n",
    "    importances = get_importances(best_model_name, model_step_name)\n",
    "    if importances is not None and len(importances)>0 :\n",
    "        # print(importances)\n",
    "        num_original_features = X_train.shape[1]\n",
    "        # Remove 'x0', 'x1' prefix from feature names\n",
    "        feature_names = [name.replace('x0', 'x1').replace('x1', 'x2') for name in feature_names]\n",
    "        print(f\"Originally, X_train contains {num_original_features} columns.\")\n",
    "        print(f\"after fitting the model, features become {len(feature_names)},\")\n",
    "        print(f\" and the feature importances contain {len(importances)} values.\")\n",
    "\n",
    "        if len(importances) <= len(feature_names)+1 :\n",
    "            if len(importances) == len(feature_names)+1:\n",
    "                print(\"Removing const importance...\")\n",
    "                importances = importances[1:]\n",
    "            # Create a DataFrame to sort and display feature importances\n",
    "            # Reshape importances array if necessary\n",
    "            importances = np.ravel(importances)\n",
    "        else:\n",
    "            # calculate the interaction terms from the feature_names \n",
    "            # importances are just importances for the original columns from X_train\n",
    "            importances_original = importances\n",
    "            importances_interaction = []\n",
    "\n",
    "            for name in feature_names[num_original_features:]:\n",
    "                # Split the term into components if there are spaces (' ')\n",
    "                components = name.split(' ')\n",
    "                importance_interaction=1\n",
    "                for component in components:\n",
    "                    if '^' in component:\n",
    "                        base, power =component.split('^')\n",
    "                    else: \n",
    "                        base =component\n",
    "                        power =1 \n",
    "\n",
    "                    base_index= feature_names.index(base)\n",
    "                \n",
    "                    importance_component = importances_original[base_index] ** int(power)\n",
    "                    \n",
    "                    importance_interaction *= importance_component\n",
    "                # Append the importance of the interaction term to the list\n",
    "                importances_interaction.append(importance_interaction)\n",
    "\n",
    "            # Combine the importances for original columns and interaction terms\n",
    "            importances = np.concatenate((importances_original, importances_interaction))\n",
    "\n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importances\n",
    "        }).sort_values(by='importance', ascending=False)\n",
    "        # Get the top rows\n",
    "        # feature_importance_df = feature_importance_df.head(top_importances)\n",
    "    else: \n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': 0\n",
    "        })\n",
    "        print(\"The model does not have feature importances or coefficients.\")\n",
    "    # print(feature_importance_df)\n",
    "\n",
    "    return best_model_name, best_model_info, feature_names, feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b827a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Model Evaluation\n",
    "# 4.1 Subfuntion\n",
    "def get_pipeline_model(model_name, model_step_name):\n",
    "# best_model_name=\"Random Forest Classifier (Degree 1)\"\n",
    "# model_step_name = 'classification_model'\n",
    "    pipeline = load(f'{model_name}.joblib')\n",
    "    for step_name in pipeline.named_steps.keys():        \n",
    "        if model_step_name == step_name: \n",
    "            model = pipeline.named_steps[model_step_name]\n",
    "            return pipeline, model\n",
    "        \n",
    "    print(f\"{model_step_name} is not valid in {pipeline.named_steps.keys()}\")\n",
    "    # importances = model.best_estimator_.feature_importances_\n",
    "    # importances\n",
    "    \n",
    "pipeline_decision, _ = get_pipeline_model('pipeline_decision','classification_model')\n",
    "# pipeline_decision = load('pipeline_decision.joblib')\n",
    "print(len(pipeline_decision.steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31619c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Plot for model performance\n",
    "def plot_all_metrics(best_model_name, best_model_info, X,y, testsize,model_step_name,feature_importance_df, top_importances, random_seed, categorical_columns ):\n",
    "    \n",
    "    # 1. Split the data using the same random_seed\n",
    "    try:\n",
    "        X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, y, test_size=testsize,  random_state=random_seed)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_test_1, y_test_1, test_size=testsize, stratify=y_test_1, random_state=42)\n",
    "\n",
    "        # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testsize, stratify=y, random_state=random_seed)\n",
    "        print(f\"X_train contains {len(X_train)} rows.\")\n",
    "        print(f\"X_test contains {len(X_test)} rows.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while splitting the data: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # train_data = X[X['Year']<=random_seed]\n",
    "    # test_data = X[X['Year']>random_seed]\n",
    "    # X_train = train_data.drop(columns=[target_variable])\n",
    "    # y_train = train_data[target_variable]\n",
    "    # X_test = test_data.drop(columns=[target_variable])\n",
    "    # y_test = test_data[target_variable]\n",
    "    \n",
    "    \n",
    "    metrics_to_plot = [\n",
    "        # (plot_confusion_matrix, 'Multiclass Confusion Matrix'),\n",
    "        # (plot_roc_curve, 'Receiver Operating Characteristic (ROC) Curve'),\n",
    "        # (plot_precision_recall_curve, 'Precision-Recall Curve'),\n",
    "        # (plot_calibration_curve, 'Calibration Curve'),\n",
    "        # (plot_feature_importances, 'Feature Importances'),\n",
    "        # (plot_combined_metrics, 'F1 Score, Specificity and MCC')\n",
    "        # (plot_f1_score, 'F1 Score'),\n",
    "        # (plot_specificity, 'Specificity'),\n",
    "        # (plot_mcc, 'Matthews Correlation Coefficient (MCC)')       \n",
    "    ]\n",
    "    # 2. Load pipeline before plotting\n",
    "    pipeline, _ = get_pipeline_model(best_model_name, model_step_name)\n",
    "    # Define metrics to plot\n",
    "    # plot_class_distribution(categorical_columns, X)\n",
    "    # plot_classification_report(pipeline,X_test, y_test)\n",
    "    # plot_decision_boundary(pipeline, X_train,y_train,model_step_name)\n",
    "    plot_decision_boundary_2(pipeline, X_train,y_train,X_test, y_test,model_step_name)\n",
    "    \n",
    "    # 3. Create the figure and axes\n",
    "    num_metrics = len(metrics_to_plot)\n",
    "    num_cols = 3\n",
    "    num_rows = (num_metrics + num_cols - 1) // num_cols\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10*num_cols, 6*num_rows))\n",
    "\n",
    "    # Adjust the spacing between subplots\n",
    "    plt.subplots_adjust(wspace=1, hspace=1) \n",
    "\n",
    "    # Flatten the axes array\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Loop over the metrics and titles, plotting each one\n",
    "    for i, (plot_function, function_title) in enumerate(metrics_to_plot):\n",
    "        # if 'ROC' in function_title:\n",
    "        #     legend_elements =[]\n",
    "        #     for a, single_model in enumerate(['Random Forest Classifier (Degree 1)', 'Decision Tree Classifier (Degree 1)', 'K-Neighbors Classifier (Degree 1)']):\n",
    "        #         # Plot multiple models in one graph\n",
    "        #         single_pipeline, _ = get_pipeline_model(single_model, model_step_name)\n",
    "        #         plot_color = get_color(a)\n",
    "        #         legend_elements.append(Line2D([0], [0], color=plot_color, lw=2, label=single_model))\n",
    "        #         plot_function(single_pipeline,X_test, y_test, plot_color, 0.3+0.1*a,legend_elements, ax=axes[i])\n",
    "                \n",
    "        if function_title == 'Feature Importances':\n",
    "            plot_function(pipeline,X_test, y_test, feature_importance_df, top_importances,ax=axes[i])\n",
    "        elif function_title =='F1 Score, Specificity and MCC':\n",
    "            \n",
    "            plot_function(best_model_info, ax=axes[i])\n",
    "        else:\n",
    "            plot_function(pipeline,X_test, y_test, ax=axes[i])\n",
    "        # Set title for the subplot\n",
    "        axes[i].set_title(f'{i+1}. {function_title}\\nsk-learn')\n",
    "\n",
    "    # Hide any empty grid cells\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot 4.1 - Class Distribution\n",
    "def plot_class_distribution(categorical_columns,X):\n",
    "    class_distribution = pd.DataFrame(columns=['Column', 'Class', 'Percentage'])\n",
    "\n",
    "    for column in categorical_columns:\n",
    "        categorical_columns_collected = [col for col in X.columns if col.startswith(column)]\n",
    "        # print(categorical_columns_collected)\n",
    "        for column_name in categorical_columns_collected:\n",
    "            # Extract the class from the column name\n",
    "            class_label = column_name.split('_')[-1]\n",
    "            # Count the values for the current column\n",
    "            value_count = X[column_name].value_counts().get(1, 0)\n",
    "            # Calculate percentages\n",
    "            percentage= (value_count/len(X))*100\n",
    "         \n",
    "            # Combine column name, class, and percentage into a DataFrame\n",
    "            temp_df = pd.DataFrame({'Column': column_name, 'Class': class_label, 'Percentage': percentage},  index=[0])\n",
    "            # print(f\"temp_df is {temp_df}\")\n",
    "            # Append to the main DataFrame\n",
    "            class_distribution = pd.concat([class_distribution, temp_df], ignore_index=True)\n",
    "\n",
    "        # Plot the class distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(class_distribution['Class'], class_distribution['Percentage'])\n",
    "        # sns.barplot(x='Class', y='Percentage', data=class_distribution, palette='viridis')\n",
    "\n",
    "        plt.xlabel(f'Class Label of {column}')\n",
    "        plt.ylabel('Percentage')\n",
    "        # plt.title(f'Classification Distribution of {column_name}')\n",
    "        plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "        plt.show()\n",
    "\n",
    "# Plot 4.2 - Classification Report\n",
    "def plot_classification_report(pipeline,X_test, y_test):\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    # Generate the classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "\n",
    "# Plot 4.3 - Multiclass Confusion Matrix\n",
    "def plot_confusion_matrix(pipeline ,X_test, y_test, ax):\n",
    "    # Load pipeline before use\n",
    "    # pipeline = load(f'{best_model_name}.joblib')\n",
    " \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    # Extract unique class names from y_true\n",
    "    class_names = np.unique(y_test)\n",
    "    class_names_str = [f'Class {int(name)}' for name in class_names]  # Convert to string if needed\n",
    "    print(class_names)\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=class_names)\n",
    "    print(cm)\n",
    "\n",
    "    if ax is None: \n",
    "        ax =plt.gca()  # Get the current Axes instance if none is provided\n",
    "    # sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False, ax=ax)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names_str, yticklabels=class_names_str, ax =ax)\n",
    "\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')    \n",
    "    \n",
    "    # Free up memory after use\n",
    "    del pipeline \n",
    "\n",
    "# Plot 4.4 - ROC Curve\n",
    "# def plot_roc_curve(pipeline,X_test,y_test,  plot_color = get_color(0), plot_alpha =1 ,legend_elements = None, ax):\n",
    "def plot_roc_curve(pipeline,X_test,y_test,ax):\n",
    "    # Load pipeline before use\n",
    "    # pipeline = load(f'{best_model_name}.joblib')\n",
    "    # y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Predict probabilities for each class\n",
    "    if hasattr(pipeline, \"predict_proba\"):  # Check if model has predict_proba method\n",
    "        y_prob = pipeline.predict_proba(X_test)\n",
    "    else:\n",
    "        y_prob = pipeline.decision_function(X_test)\n",
    "    # y_prob = pipeline.predict_proba(X_test)\n",
    "    class_names = np.unique(y_test)\n",
    "    # print(f\"Unique values in y_test : {class_names}\")\n",
    "    num_classes = len(class_names)\n",
    "    # Compute ROC Curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    # Convert multi-class labels to binary labels for each class\n",
    "    \n",
    "    # Initialize LabelBinarizer\n",
    "    binarizer = LabelBinarizer()\n",
    "    # Fit and transform y_test to obtain binary labels\n",
    "    binary_labels = binarizer.fit_transform(y_test)\n",
    "    # column_counts = np.sum(binary_labels, axis =0)\n",
    "    # for class_index, count in enumerate(column_counts):\n",
    "    #     print(f'Class {class_index+1} : {count}')\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(binary_labels[:, i], y_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Plot ROC Curve for each class\n",
    "    for i in range(num_classes):\n",
    "        ax.plot(fpr[i], tpr[i], label=f'Class {i+1} (AUC = {roc_auc[i]:.2f})', alpha=1)\n",
    "        ax.fill_between(fpr[i], tpr[i])\n",
    "   \n",
    "    ax.plot([0, 1], [0, 1], 'k--', lw=2)  # Plot diagonal line for reference\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    # ax.legend(handles = legend_elements, loc='best', title ='Models')\n",
    "    ax.legend(loc='best' , title = 'Random Forest Classifier')\n",
    "\n",
    "    del pipeline\n",
    "\n",
    "# Plot 4.5 - Precision-Recall Curve\n",
    "def plot_precision_recall_curve(pipeline,X_test, y_test, ax):\n",
    "    if hasattr(pipeline, \"predict_proba\"):  # Check if model has predict_proba method\n",
    "        y_prob = pipeline.predict_proba(X_test)\n",
    "    else:\n",
    "        y_prob = pipeline.decision_function(X_test)\n",
    "\n",
    "    class_names = np.unique(y_test)\n",
    "    # print(f\"Unique values in y_test : {class_names}\")\n",
    "    num_classes = len(class_names)\n",
    "    # Initialize LabelBinarizer\n",
    "    binarizer = LabelBinarizer()\n",
    "    # Fit and transform y_test to obtain binary labels\n",
    "    binary_labels = binarizer.fit_transform(y_test)\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    for i in range(num_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(binary_labels[:, i], y_prob[:, i])\n",
    "        ax.plot(recall[i], precision[i], label='Class %s' % class_names[i])\n",
    "\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.legend()\n",
    "\n",
    "    del pipeline\n",
    "\n",
    "# Plot 4.6 - Calibration_curve\n",
    "def plot_calibration_curve(pipeline,X_test,y_test, ax):\n",
    "   \n",
    "    if hasattr(pipeline, \"predict_proba\"):  # Check if model has predict_proba method\n",
    "        y_prob = pipeline.predict_proba(X_test)\n",
    "    else:\n",
    "        y_prob = pipeline.decision_function(X_test)\n",
    "\n",
    "    class_names = np.unique(y_test)\n",
    "    # print(f\"Unique values in y_test : {class_names}\")\n",
    "    num_classes = len(class_names)\n",
    "    # Initialize LabelBinarizer\n",
    "    binarizer = LabelBinarizer()\n",
    "    # Fit and transform y_test to obtain binary labels\n",
    "    binary_labels = binarizer.fit_transform(y_test)\n",
    "  \n",
    "    # Divide Data into Bins\n",
    "    bins = np.linspace(0,1,10)\n",
    "    # Calculate Calibration Curves for Each Class\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        prob_true, prob_pred = calibration_curve(binary_labels[:, i], y_prob[:, i], n_bins=10)\n",
    "        \n",
    "        # Plot Calibration Curve for Current Class\n",
    "        ax.plot(prob_pred, prob_true, marker='o', linestyle='-', label=f'Class {class_name} Calibration')\n",
    "        ax.plot([0, 1], [0, 1], linestyle='--', color='gray')  # Diagonal line for perfect calibration\n",
    "\n",
    "    ax.set_xlabel('Mean Predicted Probability')\n",
    "    ax.set_ylabel('Fraction of Positives')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    del pipeline\n",
    "\n",
    "# Plot 4.7 Feature Importances or Coefficients\n",
    "def plot_feature_importances(pipeline, X_test, y_test,feature_importance_df,top_importances, ax):\n",
    "   \n",
    "    top_feature_importance = feature_importance_df.head(12)\n",
    "    ax.hlines(y=top_feature_importance['feature'], xmin=0, xmax=top_feature_importance['importance'], color='skyblue')\n",
    "    ax.plot(top_feature_importance['importance'], top_feature_importance['feature'], 'o', color='skyblue')\n",
    "    ax.set_xlabel(f'Top {top_importances} Feature')\n",
    "    ax.set_ylabel('Feature')\n",
    "    ax.tick_params(axis='x', rotation=45)  # Rotate x-axis labels for better readability\n",
    "    \n",
    "# Plot 4.8 Combine below 3 metric into a single chart\n",
    "# Combine all plots into one\n",
    "def plot_combined_metrics(best_model_info, ax):\n",
    "\n",
    "    # Replace these placeholders with your actual metric values\n",
    "    metrics = {\n",
    "        'F1 Score': best_model_info['F1 Score'],\n",
    "        'Specificity': best_model_info['Specificity'],\n",
    "        'MCC': best_model_info['MCC']\n",
    "    }\n",
    "\n",
    "    colors = ['green', 'orange', 'purple']\n",
    "    positions = np.arange(len(metrics))\n",
    "\n",
    "    for i, (metric_name, metric_value) in enumerate(metrics.items()):\n",
    "        ax.bar(positions[i], metric_value, color=colors[i], label=metric_name)\n",
    "\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_xticks(positions)\n",
    "    ax.set_xticklabels(metrics.keys())\n",
    "    ax.legend()\n",
    "\n",
    "# Plot 4.9 - Desicion Boundary \n",
    "def plot_decision_boundary(pipeline, X_train,y_train,model_step_name, ax=None):\n",
    "    \n",
    "    # The original best model we chose previously only accepts X as valid input\n",
    "    # So we will add pca step into the pipeline after the preprocessor\n",
    "\n",
    "    pipeline_clone=clone(pipeline)\n",
    "    # Add PCA step to the existing pipeline\n",
    "    existing_steps = pipeline_clone.steps\n",
    "    pca = PCA(n_components=2)\n",
    "    # Insert pca before the last step --> best estimator --> (model + grid search)\n",
    "    new_steps = existing_steps[:-1] + [('pca', pca)] + existing_steps[-1:]\n",
    "\n",
    "    pipeline_decision = Pipeline(new_steps)\n",
    "    # print(pipeline_decision.steps)\n",
    "    \n",
    "    print(\"Starting training pipeline for desicion boundary...\")\n",
    "    start_time =time.time()\n",
    "    pipeline_decision.fit(X_train, y_train)\n",
    "    print(\"Training Complete.\")\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    minutes = int(execution_time // 60)\n",
    "    seconds = int(execution_time % 60)\n",
    "    print(\"Execution time:\", minutes, \"minutes and\", seconds, \"seconds\")\n",
    "    dump(pipeline_decision, \"pipeline_decision.joblib\")\n",
    "    steps = pipeline_decision.steps\n",
    "    X_train_transformed = X_train.copy()  # Make a copy of X_train\n",
    "    for step_name, transformer in steps:\n",
    "        print(step_name, \":\", transformer)\n",
    "        if step_name == model_step_name:\n",
    "            continue\n",
    "        # Transform the data using the current transformer\n",
    "        X_train_transformed = transformer.transform(X_train_transformed)\n",
    "\n",
    "    # Extract the best estimator from the pipeline\n",
    "    best_estimator_with_grid = pipeline_decision.named_steps[model_step_name].best_estimator_\n",
    "    \n",
    "    # Plot decision boundaries\n",
    "    if ax is None:\n",
    "        fig, ax= plt.subplots(figsize=(10,8))\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        best_estimator_with_grid,\n",
    "        X_train_transformed,\n",
    "        cmap = plt.cm.Paired,\n",
    "        ax = ax, \n",
    "        response_method= 'predict',\n",
    "        xlabel=\"Principal Component 1\",\n",
    "        ylabel=\"Principal Component 2\"    \n",
    "    )\n",
    "    plt.axis('tight')\n",
    "    ax.set_xlim(X_train_transformed[:, 0].min() - 0.5, X_train_transformed[:, 0].max() + 0.5)  # Adjust x-axis limits\n",
    "    ax.set_ylim(X_train_transformed[:, 1].min() - 0.5, X_train_transformed[:, 1].max() + 0.5)  # Adjust y-axis limits\n",
    "\n",
    "    # Increase point size and reduce transparency for better visibility\n",
    "    ax.scatter(X_train_transformed[:, 0], X_train_transformed[:, 1], c=y_train, cmap=plt.cm.Paired, edgecolor=\"black\", s=40, alpha=0.7)\n",
    "\n",
    "    plt.title(\"Decision boundary of Random Forest classifier on covertype dataset (PCA)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6573132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Main Scripts\n",
    "def main():\n",
    "    # 2. Load the Dataset ()\n",
    "    try:\n",
    "        dataset_name ='covertype'\n",
    "        data = load_dataset(dataset_name)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the dataset: {e}\")\n",
    "        exit()\n",
    "   \n",
    "    # Specify the target variable\n",
    "    target_variable = 'Cover_Type'\n",
    "    # Check if data is already a DataFrame\n",
    "   \n",
    "    try:\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            print(f\"Converting {dataset_name} from {type(data)} to a data frame.\")\n",
    "            if isinstance(data, str):\n",
    "                data_frame = pd.read_csv(io.StringIO(data))\n",
    "            elif isinstance(data, Bunch):\n",
    "                # Convert the data to a DataFrame\n",
    "                data_frame = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "                data_frame[target_variable]= data.target\n",
    "                \n",
    "            else:\n",
    "                data_frame = pd.DataFrame(data)\n",
    "        else:\n",
    "            print(f\"Data from {dataset_name} is already a data frame.\")\n",
    "            data_frame =data\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "    transformed_data = data_frame.copy()\n",
    "    y = transformed_data[target_variable]\n",
    "\n",
    "    # Identifying the feature types\n",
    "    numeric_features =[]\n",
    "    categorical_columns = ['Soil_Type_', 'Wilderness_Area_']\n",
    "    # Loop through columns to find numeric features\n",
    "    for col in transformed_data.columns:\n",
    "        if col.startswith(tuple(categorical_columns)):\n",
    "            continue  # Skip categorical columns\n",
    "        if transformed_data[col].dtype in ['int64', 'float64']:\n",
    "            numeric_features.append(col)\n",
    "   \n",
    "\n",
    "    # Check and convert Binary columns\n",
    "    soil_type_columns = [col for col in transformed_data.columns if col.startswith('Soil_Type')]\n",
    "    wilderness_area_columns = [col for col in transformed_data.columns if col.startswith('Wilderness_Area')]\n",
    "\n",
    "    # Function to check if columns are binary or non-binary, including handling of null values\n",
    "    def check_binary_columns(data, columns):\n",
    "        binary_columns = []\n",
    "        non_binary_columns = []\n",
    "        for col in columns:\n",
    "            unique_values = data[col].dropna().unique()\n",
    "            if set(unique_values) <= {0, 1}:\n",
    "                binary_columns.append(col)\n",
    "            else:\n",
    "                non_binary_columns.append(col)\n",
    "        return binary_columns, non_binary_columns\n",
    "\n",
    "    soil_type_binary, soil_type_non_binary = check_binary_columns(transformed_data, soil_type_columns)\n",
    "    wilderness_area_binary, wilderness_area_non_binary = check_binary_columns(transformed_data, wilderness_area_columns)\n",
    "\n",
    "    categorical_binary_features = soil_type_binary + wilderness_area_binary\n",
    "    categorical_non_binary_features = soil_type_non_binary + wilderness_area_non_binary\n",
    "    print(categorical_non_binary_features)\n",
    "    # Includes all features\n",
    "    all_features = numeric_features + categorical_binary_features + categorical_non_binary_features\n",
    "\n",
    "    # Define X\n",
    "    X = transformed_data[all_features]\n",
    "\n",
    "    # Handling missing values and scaling numerical features\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Transformer for binary categorical features\n",
    "    binary_categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent'))  # Impute missing values for binary categorical features\n",
    "    ])\n",
    "\n",
    "    # Combine imputer and onehot for non-binary categorical features\n",
    "    non_binary_categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    # Create Proprecessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numeric_features),\n",
    "            ('binary_cat', binary_categorical_transformer, categorical_binary_features),  \n",
    "            ('non_binary_cat', non_binary_categorical_transformer, categorical_non_binary_features)\n",
    "        ]\n",
    "    )  \n",
    "      \n",
    "    top_importances =12\n",
    "    testsize=0.2\n",
    "    # random_seed=42\n",
    "    # Or devide the datasets similar to 'Smarket' by year\n",
    "    random_seed = 2004\n",
    "    model_step_name = 'classification_model'\n",
    "    best_model_name = None\n",
    "    best_model_name, best_model_info, feature_names, feature_importance_df = fit_classification_models(X,y,testsize,model_step_name, preprocessor, target_variable,random_seed, top_importances)\n",
    "\n",
    "    # feature_importance_df contains importances for all 40 soil types, aggregate them all\n",
    "    feature_importance_df = get_feature_importance_df()\n",
    "    # Loop through each prefix in the categorical_list\n",
    "    for prefix in categorical_columns:\n",
    "        # Filter the DataFrame to select features starting with the current prefix\n",
    "        categorical_features = feature_importance_df[feature_importance_df['feature'].str.startswith(prefix)]\n",
    "        # Insert the prefix as a new row into the DataFrame\n",
    "        feature_importance_df.loc[len(feature_importance_df)] = {\n",
    "            'feature': prefix, \n",
    "            'importance': categorical_features['importance'].sum()\n",
    "        }\n",
    "        \n",
    "    # Sort the DataFrame based on the new values\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "    # as there are aggregation values in the feature_importance_df,\n",
    "    # it is not suitable to plot for these aggregated columns\n",
    "    # Extract the top_features from feature_importance_df\n",
    "    top_features =feature_importance_df['feature'].tolist()[:top_importances]\n",
    "    # Loop through each prefix in the categorical_columns\n",
    "    for prefix in categorical_columns:\n",
    "        # Filter the DataFrame to select rows where 'feature' column matches the current prefix\n",
    "        if prefix in top_features:\n",
    "            top_features.remove(prefix)\n",
    "\n",
    "    # Display the updated DataFrame\n",
    "    print(f\"top_features are {top_features}\")\n",
    "\n",
    "    # 6. Visualize Model Performance \n",
    "    if best_model_name is None:\n",
    "        best_model_info = \"1\"\n",
    "        best_model_name = \"Random Forest Classifier (Degree 1)\"\n",
    "    plot_all_metrics(best_model_name, best_model_info, X,y, testsize,model_step_name,feature_importance_df, top_importances, random_seed, categorical_columns)\n",
    "    \n",
    "    # 7. Predicting with the best model\n",
    "    if best_model_name: \n",
    "        # Load pipeline before use\n",
    "        pipeline = load(f'{best_model_name}.joblib')\n",
    "        new_data = X[0:5]  # Just an example of new data\n",
    "        predictions = pipeline.predict(new_data)\n",
    "        print(\"Predictions on new data:\", predictions)\n",
    "    else:\n",
    "        print(\"Can't find the best model.\")\n",
    "    del pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "###### scikit-learn/classification ######"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "497a84dc8fec8cf8d24e7e87b6d954c9a18a327edc66feb9b9ea7e9e72cc5c7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
